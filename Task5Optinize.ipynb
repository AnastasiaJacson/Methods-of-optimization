{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "import numpy.linalg as ln\n",
    "import random\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(x):\n",
    "    \n",
    "    global calls\n",
    "    calls += 1\n",
    "    \n",
    "    n = len(x)\n",
    "    res = 0\n",
    "    for i in range(n - 1):\n",
    "        res += 100.0 * (x[i + 1] - x[i]**2)**2 + (1 - x[i])**2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calls = 0\n",
    "\n",
    "\n",
    "epsilon = 1e-7\n",
    "delta = 1e-3\n",
    "n_sum = int (input(\"enter N:\"))\n",
    "\n",
    "#x0 = np.array([float(val) for val in input(\"Введіть початкову точку x0 через пробіл: \").split()])\n",
    "#x0 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0])\n",
    "x0 = np.full(n_sum, 0)\n",
    "max_iterations = int(input(\"Введіть максимальну кількість ітерацій (K < 1000): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock_gradient(x):\n",
    "    \n",
    "    global calls\n",
    "    calls += len(x)\n",
    "    \n",
    "    if len(x) < 2:\n",
    "        raise ValueError(\"Для обчислення градієнта x повинен мати розмірність принаймні 2.\")\n",
    "    \n",
    "    n = len(x)\n",
    "    gradient = np.zeros_like(x)\n",
    "    gradient[0] = -400 * x[0] * (x[1] - x[0]**2) - 2 * (1 - x[0])\n",
    "    gradient[1:-1] = 200 * (x[1:-1] - x[:-2]**2) - 400 * x[1:-1] * (x[2:] - x[1:-1]**2) - 2 * (1 - x[1:-1])\n",
    "    gradient[-1] = 200 * (x[-1] - x[-2]**2)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def golden_section_search(f, a, b, tol=1e-5):\n",
    "    gr = (np.sqrt(5) + 1) / 2 - 1\n",
    "    c = b - gr * (b - a)\n",
    "    d = a + gr * (b - a)\n",
    "\n",
    "    while abs(c - d) > tol:\n",
    "        if f(c) < f(d):\n",
    "            b = d\n",
    "        else:\n",
    "            a = c\n",
    "\n",
    "        c = b - gr * (b - a)\n",
    "        d = a + gr * (b - a)\n",
    "\n",
    "    return (b + a) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs_method(x0, elipson, delta, K):\n",
    "    x = x0\n",
    "    k = 0\n",
    "    N = len(x0)\n",
    "    I = np.eye(N, dtype=int)\n",
    "    Hk = I\n",
    "   #################\n",
    "    gradient = rosenbrock_gradient(x)\n",
    "    \n",
    "\n",
    "    while ln.norm(gradient) > elipson and k < K:\n",
    "        f_x = rosenbrock(x)\n",
    "    \n",
    "        pk = -np.dot(Hk, gradient)\n",
    "\n",
    "        objective_function = lambda alpha: rosenbrock(x + alpha * pk)\n",
    "        alpha_k = golden_section_search(objective_function, 0, 1, tol=delta)\n",
    "\n",
    "        xkp1 = x + alpha_k * pk\n",
    "        sk = xkp1 - x\n",
    "        x = xkp1\n",
    "\n",
    "        fderxp1 = rosenbrock_gradient(xkp1)\n",
    "        yk = fderxp1 - gradient\n",
    "        gradient = fderxp1\n",
    "\n",
    "\n",
    "        k += 1\n",
    "        \n",
    "        ro = 1.0 / (np.dot(yk, sk))\n",
    "        A1 = I - ro * sk[:, np.newaxis] * yk[np.newaxis, :]\n",
    "        A2 = I - ro * yk[:, np.newaxis] * sk[np.newaxis, :]\n",
    "        Hk = np.dot(A1, np.dot(Hk, A2)) + (ro * sk[:, np.newaxis] * sk[np.newaxis, :])\n",
    "        \n",
    "    return x, f_x, np.linalg.norm(pk), k\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal point: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1.]\n",
      "Optimal value: 7.745732094279547e-17\n",
      "Norm of gradient: 9.418821712534409e-10\n",
      "Number of iterations: 124\n",
      "Number of gradient calls:  15600\n"
     ]
    }
   ],
   "source": [
    "result = bfgs_method(x0, epsilon, delta, max_iterations)\n",
    "\n",
    "print(\"Optimal point:\", result[0])\n",
    "print(\"Optimal value:\", result[1])\n",
    "print(\"Norm of gradient:\", result[2])\n",
    "print(\"Number of iterations:\", result[3])\n",
    "print(\"Number of gradient calls: \", calls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
